---
title: "Data Exploration and Analysis - Task 1"
author: "Siddharth Gada"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  results = 'markup',
  fig.align = "center",
  fig.width = 6,
  fig.height = 4
)
options(width = 60)  # limit console output width
```

```{r Libraries, echo=FALSE, results='markup', eval=TRUE}
cat("## Chunk: Loading Libraries\n")
```

```{r }
library(data.table) 
library(ggplot2) 
library(ggmosaic) 
library(readr)
library(readxl)
library(stringr)
library(dplyr)
library(lubridate)
library(scales)
options(scipen = 999)  # Turn off scientific notation
```

```{r Loading Datasets, echo=FALSE, results='markup', eval=TRUE}
cat("## Chunk: Loading Datasets\n")
```

```{r }
transactionData <- read_excel(paste0(
  "C:/Users/gadas/OneDrive/Desktop/",
  "Classes Outside UNT/Forage Project/",
  "Quantium Data Analytics/QVI_transaction_data.xlsx"))

customerData <- read.csv(paste0(
  "C:/Users/gadas/OneDrive/Desktop/",
  "Classes Outside UNT/Forage Project/",
  "Quantium Data Analytics/QVI_purchase_behaviour.csv"))

head(transactionData)
head(customerData)
```

```{r Data Exploration Start, echo=FALSE, results='markup', eval=TRUE}
cat("## Data Exploration Start\n")
```

```{r Examining Transaction data, echo=FALSE, results='markup', eval=TRUE}
cat("## Examining Transaction Data\n")
```

```{r }
# Examine date variable from transaction data
summary(transactionData$DATE)
# Need to convert date variable from numeric to date format
transactionData$DATE_Converted <- as.Date(transactionData$DATE, 
                                          origin = "1899-12-30")

# Remove DATE column which is not converted
transactionData$DATE <- NULL

# Examine PROD_NAME
summary(transactionData$PROD_NAME)

# Split all product names into words
words <- unlist(strsplit(transactionData$PROD_NAME, "\\s+"))

# Keep only words with letters a-z or A-Z (remove digits/special chars)
clean_words <- words[!grepl("[^A-Za-z]", words)]

# Create frequency table
word_freq <- data.table(word = clean_words)[, .N, by = word]
setorder(word_freq, -N)

# Remove salsa products because we are only interested in keeping the 
# data related to chips sales
transactionData <- subset(transactionData, !grepl("salsa", tolower(PROD_NAME)))

# Summarise the data to check for nulls and possible outliers
summary(transactionData)
data.frame(
  Column = names(transactionData),
  Total_Obs = nrow(transactionData),
  Non_Missing = colSums(!is.na(transactionData)),
  Missing = colSums(is.na(transactionData))
)

# There are no nulls in the columns but product quantity appears to have an outlier
# Filter the dataset to find the outlier in product quantity 
# where 200 chip packets were bought in one transaction
setDT(transactionData)
transactionData[PROD_QTY==200]
# There are two transactions where 200 packets of chips are bought in 
# one transaction and both of these transactions were by the same customer.

# Checking if the customer has had other transactions
transactionData[LYLTY_CARD_NBR==226000]

# Looks like this customer has only had the two transactions over the year 
# and is not an ordinary retail customer. 
# The customer might be buying chips for commercial purposes instead. 
# We'll remove this loyalty card number from further analysis.
transactionData <- transactionData[LYLTY_CARD_NBR != 226000]

# Checking if all transactions from the card number have been removed
transactionData[LYLTY_CARD_NBR==226000]

# Count the number of transactions by date
transactions_by_date <- transactionData %>%
  group_by(DATE_Converted) %>%
  summarise(Transaction_Count = n())

# There's only 364 rows, meaning only 364 dates which indicates a missing date.
# Create a full sequence of dates from 1 Jul 2018 to 30 Jun 2019 and use this to 
# create a chart of number of transactions over time to find the missing date.
ALLDATES <- data.table(DATE_Converted = seq(as.Date("2018-07-01"), 
                                            as.Date("2019-06-30"), by = "day"))

# Join all_dates with transactions_by_date (left join)
fullTransactionData <- merge(ALLDATES, transactionData, by = "DATE_Converted", 
                             all.x = TRUE)

# Count the number of transactions by date to see if the missing date was added
transactions_by_date_1 <- fullTransactionData %>%
  group_by(DATE_Converted) %>%
  summarise(Transaction_Count = n())

# Setting plot themes to format graphs 
theme_set(theme_bw()) 
theme_update(plot.title = element_text(hjust = 0.5))

# Plot transactions over time 
ggplot(transactions_by_date_1, aes(x = DATE_Converted, y = Transaction_Count))+ 
  geom_line() +
  labs(x = "Day", y = "Number of Transactions", title = "Transactions over time")+
  scale_x_date(breaks = "1 month")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
# We can see that there is an increase in purchases in December and a break
# in late December. Let's zoom in on this.

# Weekly transaction plot for Presentation
fullTransactionData$WeekStart <- floor_date(fullTransactionData$DATE_Converted, 
                             unit = "week", week_start = 1)

weekly_transactions <- fullTransactionData[, .(
  weekly_transactions = uniqueN(TXN_ID)  # Count of unique transactions
), by = WeekStart][order(WeekStart)]

ggplot(weekly_transactions, aes(x = WeekStart, y = weekly_transactions))+ 
  geom_line(color = "steelblue", size = 1.5) +
  labs(x = "Month", y = "Number of Transactions", 
       title = "Weekly Transactions") +
  scale_x_date(date_breaks = "1 month", date_labels = "%b",
               limits = as.Date(c("2018-07-01", "2019-06-30")))+
  theme(axis.text.x = element_text(vjust = 0.5))

fullTransactionData$WeekStart <- NULL
weekly_transactions <- NULL

# Filter to December and look at individual days
# Filter for December 2018
setDT(transactions_by_date_1)
december_data <- transactions_by_date_1[
  transactions_by_date_1$DATE_Converted >= as.Date("2018-12-01") 
  & transactions_by_date_1$DATE_Converted <= as.Date("2018-12-31")
]

# Plot daily transactions for December
ggplot(december_data, aes(x = DATE_Converted, y = Transaction_Count))+
  geom_line(color = "darkred")+
  labs(
    x = "Date", 
    y = "Number of Transactions", 
    title = "Daily Transactions in December 2018"
  ) +
  scale_x_date(
    date_breaks = "1 day", 
    date_labels = "%d-%b"
  ) +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5),
    panel.background = element_blank(),
    panel.grid.major = element_line(color = "grey90")
  )

# We can see that the increase in sales occurs in the lead-up to Christmas and 
# that there are zero sales on Christmas day itself which was the missing date. 
# This is due to shops being closed on Christmas day.

# Creating a Pack size variable
# We can work this out by taking the digits that are in PROD_NAME 
setDT(transactionData)
transactionData[, PACK_SIZE := parse_number(PROD_NAME)]

# Checking if the pack sizes look sensible 
transactionData[, .N, PACK_SIZE][order(PACK_SIZE)]

## The largest size is 380g and the smallest size is 70g - seems sensible

# Histogram of PACK_SIZE
# Treat PACK_SIZE as a factor (categorical)
ggplot(transactionData, aes(x = factor(PACK_SIZE)))+  
  geom_bar(fill = "steelblue")+
  labs(
    x = "Pack Size", 
    y = "Count", 
    title = "Distribution of Pack Size"
  )+
  theme_minimal()

# Creating a Brand variable
# We can work this out by taking the first word that is in PROD_NAME 
transactionData[, Brand := ifelse(is.na(PROD_NAME), NA, 
                                      tstrsplit(PROD_NAME, " ")[[1]])]
# Finding out unique Brand names
unique(transactionData$Brand)

# Clean Brand names
transactionData[Brand == "Red", Brand := "RRD"]
transactionData[Brand == "Smith", Brand := "Smiths"]
transactionData[Brand == "Infzns", Brand := "Infuzions"]
transactionData[Brand == "Snbts", Brand := "Sunbites"]
transactionData[Brand == "WW", Brand := "Woolworths"]
transactionData[Brand == "NCC", Brand := "Natural"] 
transactionData[Brand == "Dorito", Brand := "Doritos"] 
transactionData[Brand == "Grain", Brand := "GrnWves"]

# Checking if any more discrepancies in names
unique(transactionData$Brand)

# Clean each PROD_NAME by removing words that contain non-letter characters
transactionData[, PROD_NAME := sapply(strsplit(PROD_NAME, "\\s+"), 
                                          function(words) {
  clean_words <- words[!grepl("[^A-Za-z]", words)]
  paste(clean_words, collapse = " ")
})]
```

```{r Examining Customer Data, echo=FALSE, results='markup', eval=TRUE}
cat("## Examining Customer Data\n")
```

```{r }
# Making sure there are no missing values
summary(customerData)
length(customerData$LYLTY_CARD_NBR)

length(unique(transactionData$LYLTY_CARD_NBR))

# Performing a left join because we only want matches from 'transactionData'
# since 'customerData' has customer 226000 which we excluded from our dataset 
# because he buys for commercial use
# This is the reason we did not want to delete the customers that bought SALSA 
# so that we get exact matches from the two datasets.

data <- merge(transactionData, customerData, all.x = TRUE)

length(unique(data$LYLTY_CARD_NBR))

# Check if some customers were not matched on by checking for nulls.
sum(is.na(data$LYLTY_CARD_NBR))
sum(is.na(data$LIFESTAGE))
sum(is.na(data$PREMIUM_CUSTOMER))

# Code to save dataset as a csv
write.csv(data,
          file = paste0(
  "C:/Users/gadas/OneDrive/Desktop/",
  "Classes Outside UNT/Forage Project/",
  "Quantium Data Analytics/QVI_data.csv"))
```

```{r Data analysis on customer segments Start, echo=FALSE, results='markup', eval=TRUE}
cat("## Data analysis on customer segments Start\n")
```

```{r Total sales by Loyalty Card Number, echo=FALSE, results='markup', eval=TRUE}
cat("## Chunk: Total sales by Loyalty Card Number\n")
```

```{r }
data[, .(Total_Spend = sum(TOT_SALES)), by = .(LYLTY_CARD_NBR)][order(-Total_Spend)]
```

```{r Total sales by Lifestage and Premium Customer, echo=FALSE, results='markup', eval=TRUE}
cat("## Chunk: Total sales by Lifestage and Premium Customer\n")
```

```{r }
# LIFESTAGE: Customer attribute that identifies whether a customer has a family 
# or not and what point in life they are at
# PREMIUM_CUSTOMER: Customer segmentation used to differentiate shoppers by the 
# price point of products they buy and the types of products they buy. 
sales_by_segment <- data[, .(Total_Spend = sum(TOT_SALES)), 
                         by = .(PREMIUM_CUSTOMER, LIFESTAGE)][order(-Total_Spend)]
# Plot the sales split
ggplot(sales_by_segment, aes(x = LIFESTAGE, y = Total_Spend, fill = PREMIUM_CUSTOMER))+
  geom_bar(stat = "identity", position = "dodge")+
  labs(title = "Total Chip Sales by Customer Segment",
       x = "Lifestage", y = "Total Spend ($)",
       fill = "Premium Customer")+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
# Sales are coming mainly from Budget - older families, 
# Mainstream - young singles/couples and Mainstream - retirees
```

```{r How many customers are in each segment, echo=FALSE, results='markup', eval=TRUE}
cat("## Chunk: How many customers are in each segment\n")
```

```{r }
# How many customers are in each segment
customers_by_segment <- data[, uniqueN(LYLTY_CARD_NBR), 
                             by = .(LIFESTAGE, PREMIUM_CUSTOMER)]
setnames(customers_by_segment, "V1", "N")
# Plot number of customers
ggplot(customers_by_segment, aes(x = LIFESTAGE, y = N, fill = PREMIUM_CUSTOMER))+
  geom_bar(stat = "identity", position = "dodge")+
  labs(title = "Number of Customers by Lifestage and Premium Status",
       x = "Lifestage", y = "Number of Customers",
       fill = "Premium Customer")+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
# There are more Mainstream - young singles/couples and Mainstream - retirees who buy chips. 
# This contributes to there being more sales to these customer segments but this
# is not a major driver for the Budget - Older families segment.

# Percentage of Customers by Lifestage and Premium Status plot for Presentation
customers_by_segment_pct <- customers_by_segment %>%
  group_by(LIFESTAGE) %>%
  mutate(pct = N / sum(N),
         pct = pct / sum(pct),
         total_N = sum(N)) %>%
  ungroup()

ggplot(customers_by_segment_pct, aes(x = LIFESTAGE, y = pct, fill = PREMIUM_CUSTOMER))+
  geom_bar(stat = "identity", position = "stack") +
  geom_text(aes(label = scales::percent(pct, accuracy = 1)),
            position = position_stack(vjust = 0.5),
            size = 3, color = "white") +
  geom_text(data = customers_by_segment_pct %>%
              distinct(LIFESTAGE, total_N),
            aes(x = LIFESTAGE, y = 1.05, 
                label = paste(scales::number(total_N / 1000, accuracy = 0.1), "K")),
            inherit.aes = FALSE) +
  annotate("text", x = length(unique(customers_by_segment_pct$LIFESTAGE)) / 2 + 0.5,
           y = 1.12, label = "Num of Customers") +
  labs(title = "Percentage of Customers by Lifestage and Premium Status",
       x = "Lifestage", y = "Percentage of Customers",
       fill = "Premium Customer")+
  scale_y_continuous(labels = percent_format(), limits = c(0, 1.15), expand = c(0,0)) +
  scale_fill_manual(values = c("Budget" = "#c6dbef",    # light blue
                               "Mainstream" = "#6baed6", # medium blue
                               "Premium" = "#2171b5")) + # dark blue
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

customers_by_segment_pct <- NULL
```

```{r How many chips are bought per customer by segment, echo=FALSE, results='markup', eval=TRUE}
cat("## Chunk: How many chips are bought per customer by segment\n")
```

```{r }
avg_units_per_customer <- data[, .(Num_Chips_bought = sum(PROD_QTY),
         Unique_Customers = uniqueN(LYLTY_CARD_NBR)), 
         by = .(PREMIUM_CUSTOMER, LIFESTAGE)][order(-Num_Chips_bought)]
# Compute average units per customer
avg_units_per_customer[, Avg_Units := Num_Chips_bought / Unique_Customers]
# Plot
ggplot(avg_units_per_customer, aes(x = LIFESTAGE, y = Avg_Units, fill = PREMIUM_CUSTOMER))+
  geom_bar(stat = "identity", position = "dodge")+
  labs(title = "Average Chip Units per Customer by Segment",
       x = "Lifestage", y = "Average Units",
       fill = "Premium Customer")+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
# Older families and young families in general buy more chips per customer

# Plot for Presentation
ggplot(avg_units_per_customer, aes(x = LIFESTAGE, y = Avg_Units, fill = PREMIUM_CUSTOMER))+
  geom_bar(stat = "identity", position = "dodge")+
  labs(title = "Average Chip Units per Customer by Segment",
       x = "Lifestage", y = "Average Units",
       fill = "Premium Customer")+
  scale_fill_manual(values = c("Budget" = "#c6dbef",    # light blue
                               "Mainstream" = "#6baed6", # medium blue
                               "Premium" = "#2171b5")) + # dark blue
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r Calculate average price per unit by segment, echo=FALSE, results='markup', eval=TRUE}
cat("## Chunk: Calculate average price per unit by segment\n")
```

```{r }
avg_price_data <- data[, .(  Total_Sales = sum(TOT_SALES),
                             Total_Units = sum(PROD_QTY)), 
                       by = .(LIFESTAGE, PREMIUM_CUSTOMER)]
# Compute average price per unit
avg_price_data[, Avg_Price := Total_Sales / Total_Units]
# Plot the results
ggplot(avg_price_data, aes(x = LIFESTAGE, y = Avg_Price, fill = PREMIUM_CUSTOMER))+
  geom_bar(stat = "identity", position = "dodge")+
  labs(title = "Average Price per Unit by Lifestage and Premium Status",
       x = "Lifestage", y = "Average Price",
       fill = "Premium Customer")+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
# Mainstream midage and young singles and couples are more willing to pay more 
# per packet of chips compared to their budget and premium counterparts. 
# This may be due to premium shoppers being more likely to buy healthy snacks 
# and when they buy chips, this is mainly for entertainment purposes rather than
# their own consumption. This is also supported by there being fewer premium 
# midage and young singles and couples buying chips compared to their mainstream counterparts.
```

```{r T-Tests, echo=FALSE, results='markup', eval=TRUE}
cat("## Chunk: T-Tests\n")
```

```{r }
# Perform an independent t-test between mainstream vs premium and budget 
# midage and young singles and couples
# T-test for Budget vs. Mainstream midage and young singles and couples
t.test(TOT_SALES / PROD_QTY ~ PREMIUM_CUSTOMER, 
       data = data, 
       subset = LIFESTAGE %in% c("MIDAGE SINGLES/COUPLES", "YOUNG SINGLES/COUPLES")
       & PREMIUM_CUSTOMER %in% c("Budget", "Mainstream"))
# T-test for Budget vs. Premium midage and young singles and couples
t.test(TOT_SALES / PROD_QTY ~ PREMIUM_CUSTOMER, 
       data = data, 
       subset = LIFESTAGE %in% c("MIDAGE SINGLES/COUPLES", "YOUNG SINGLES/COUPLES")
       & PREMIUM_CUSTOMER %in% c("Budget", "Premium"))
# The t-test results in a p-value of < 0.00000000000000022, i.e. the unit price 
# for mainstream, young and mid-age singles and couples ARE significantly higher
# than that of budget or premium, young and midage singles and couples.
```

```{r Calculate total sales and quantity by Brand and for Mainstream, Young singles/couples customer segment, echo=FALSE, results='markup', eval=TRUE}
cat("## Chunk: # Find out if the Mainstream, Young singles/couples 
    customer segment tend to buy a particular brand of chips\n")
```

```{r }
brand_segment <- data %>%
  group_by(LIFESTAGE, PREMIUM_CUSTOMER, Brand) %>%
  summarise(SegmentBrandQty = sum(PROD_QTY), .groups = "drop")
# Total quantity bought by each segment
segment_total <- data %>%
  group_by(LIFESTAGE, PREMIUM_CUSTOMER) %>%
  summarise(SegmentTotalQty = sum(PROD_QTY), .groups = "drop")
# Total quantity bought per brand
brand_total <- data %>%
  group_by(Brand) %>%
  summarise(BrandTotalQty = sum(PROD_QTY), .groups = "drop")
# Total quantity overall
total_qty <- sum(data$PROD_QTY)
# Merge data
affinity_data <- brand_segment %>%
  left_join(segment_total, by = c("LIFESTAGE", "PREMIUM_CUSTOMER")) %>%
  left_join(brand_total, by = "Brand") %>%
  mutate(
    SegmentBrandShare = SegmentBrandQty / SegmentTotalQty,
    BrandShareOverall = BrandTotalQty / total_qty,
    AffinityScore = SegmentBrandShare / BrandShareOverall
  )
# Focus on Mainstream Young Singles/Couples
affinity_data %>%
  filter(LIFESTAGE == "YOUNG SINGLES/COUPLES", PREMIUM_CUSTOMER == "Mainstream") %>%
  arrange(desc(AffinityScore)) %>%
  print (n=21)
# Mainstream, Young singles/couples customer segment prefer to buy chips from 
# brands like Tyrrells, Twisties, Kettle, Tostitos and Old.
# Mainstream young singles/couples are 21% more likely to buy Tyrrells chips than 
# the other customers.
# Mainstream young singles/couples are 54% less likely to purchase Burger Rings 
# compared to the overall customer base.
```

```{r Find out if our target segment tends to buy larger packs of chips, echo=FALSE, results='markup', eval=TRUE}
cat("## Chunk: Find out if our target segment tends to buy larger packs of chips\n")
```

```{r }
# Calculate average PACK_SIZE for Mainstream Young Singles/Couples
# Define your target and all other segment
target_segment <- data %>%
  filter(LIFESTAGE == "YOUNG SINGLES/COUPLES", PREMIUM_CUSTOMER == "Mainstream")
rest_segment <- data %>%
  filter(!(LIFESTAGE == "YOUNG SINGLES/COUPLES" & PREMIUM_CUSTOMER == "Mainstream"))
# Calculate proportion of each pack size in target segment
target_pack_share <- target_segment %>%
  group_by(PACK_SIZE) %>%
  summarise(TargetQty = sum(PROD_QTY)) %>%
  mutate(TotalTarget = sum(TargetQty),
         TargetProp = TargetQty / TotalTarget)
# Calculate proportion of each pack size in other segments
rest_pack_share <- rest_segment %>%
  group_by(PACK_SIZE) %>%
  summarise(RestQty = sum(PROD_QTY)) %>%
  mutate(TotalRest = sum(RestQty),
         RestProp = RestQty / TotalRest)
# Merge both and calculate affinity score
pack_affinity <- left_join(target_pack_share, rest_pack_share, by = "PACK_SIZE") %>%
  mutate(Affinity_Score = TargetProp / RestProp) %>%
  arrange(desc(Affinity_Score))
# View results
print(pack_affinity)
# It looks like Mainstream young singles/couples are 27% more likely to purchase a 270g pack of chips 
# compared to the rest of the population but let's dive into what brands sell this pack size.

# Check which products are the closest to selling 270g chip packets for targetted marketting
data[PACK_SIZE == 270, unique(PROD_NAME)]
```

```{r Conclusion, echo=FALSE, results='markup', eval=TRUE}
cat("## Conclusion\n")
```

```{r }
# Sales have mainly been due to Budget-older families,Mainstream-young singles/couples,
# and Mainstream- retirees shoppers. We found that the high spend in chips for mainstream
# young singles/couples and retirees is due to there being more of them than other buyers.
# Mainstream, midage and young singles and couples are also more likely to pay more
# per packet of chips. This is indicative of impulse buying behaviour. We've also found 
# that Mainstream young singles and couples are 23% more likely to purchase Tyrrells chips
# compared to the rest of the population. The Category Manager may want to increase the 
# category's performance by off-locating some Tyrrells and smaller packs of chips in 
# discretionary space near segments where young singles and couples frequent more often to
# increase visibilty and impulse behaviour.
```